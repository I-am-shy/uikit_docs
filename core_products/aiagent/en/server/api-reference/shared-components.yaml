openapi: 3.0.0
info:
  title: AI Agent API - 共享组件
  version: 1.0.0

servers:
  - url: https://aigc-aiagent-api.zegotech.cn
    description: Unified access address (no regional distinction)
  - url: https://aigc-aiagent-api-sha.zegotech.cn
    description: Mainland China (Shanghai)
  - url: https://aigc-aiagent-api-hkg.zegotech.cn
    description: Hong Kong, Macao, and Taiwan (Hong Kong)
  - url: https://aigc-aiagent-api-fra.zegotech.cn
    description: Europe (Frankfurt)
  - url: https://aigc-aiagent-api-lax.zegotech.cn
    description: Western United States (California)
  - url: https://aigc-aiagent-api-bom.zegotech.cn
    description: Asia-Pacific (Mumbai)
  - url: https://aigc-aiagent-api-sgp.zegotech.cn
    description: Southeast Asia (Singapore)

components:
  # 共享的参数定义
  parameters:
    # Re-export ZEGO global shared parameters for convenient local reference
    AppId:
      $ref: "../../../../../snippets/common/en/openapi/zego-shared-components.yaml#/components/parameters/AppId"
    SignatureNonce:
      name: SignatureNonce
      in: query
      description: 💡Public parameter. A 16-character hexadecimal random string (hex encoding of 8-byte random number). Refer to [Signature sample code](/aiagent-server/api-reference/accessing-server-apis#signature-sample-code) for how to generate.
      required: true
      schema:
        type: string

    Timestamp:
      name: Timestamp
      in: query
      description: 💡Public parameter. Current Unix timestamp, in seconds. Refer to [Signature sample code](/aiagent-server/api-reference/accessing-server-apis#signature-sample-code) for how to generate, with a maximum error of 10 minutes.
      required: true
      schema:
        type: integer
        format: int64
    SignatureVersion:
      $ref: "../../../../../snippets/common/en/openapi/zego-shared-components.yaml#/components/parameters/SignatureVersion"
    Signature:
      name: Signature
      in: query
      description: 💡Public parameter. Signature, used to verify the legitimacy of the request. Refer to [Signing the requests](/aiagent-server/api-reference/accessing-server-apis#signature-mechanism) for how to generate an API request signature.
      required: true
      schema:
        type: string

  schemas:
    RTC:
      type: object
      description: |
        <div>
          <p>RTC related information</p>
          <br/>
          <strong>📌 Important Note</strong>
          <p>All attribute character restrictions: only numbers, English characters, '_', '-', and '.' are supported.</p>
        </div>

      required:
        - RoomId
        - AgentStreamId
        - AgentUserId
        - UserStreamId
      properties:
        RoomId:
          type: string
          description: RTC room ID.
          maxLength: 128
          example: "room_1"
        AgentStreamId:
          type: string
          description: |
            The stream ID used by the AI agent instance for streaming.
            > **📌 Important Note**
            >
            > Ensure that multiple AI agent instances (even if they are not in the same RTC room) use different stream IDs, otherwise the streaming of the later created AI agent instance will fail.
          maxLength: 128
          example: "agent_stream_1"
        AgentUserId:
          type: string
          description: |
            The user ID of the AI agent instance.
            > **📌 Important Note**
            >
            > Ensure that multiple AI agent instances (even if they are not in the same RTC room) use different user IDs, otherwise the earlier created AI agent instance will be kicked out of the RTC room.
          maxLength: 32
          example: "agent_user_1"
        UserStreamId:
          type: string
          description: The stream ID used by the real user for streaming.
          maxLength: 128
          example: "user_stream_1"

    LLM:
      type: object
      required:
        - Url
        - Model
      properties:
        Url:
          type: string
          description: |
            The endpoint that receives the request (can be your own service or any LLM service provider's service) and must be compatible with [OpenAI Chat Completions API](https://platform.openai.com/docs/api-reference/chat).

            For example: https://api.openai.com/v1/chat/completions

            > **📌 Important Note**
            >
            > If ApiKey is set to "zego_test", you must use one of the following Url addresses:
            > - MiniMax：https://api.minimax.chat/v1/text/chatcompletion_v2
            > - Volcano Engine (Doubao): https://ark.cn-beijing.volces.com/api/v3/chat/completions
            > - Aliyun Bailei (Tongyi Qianwen): https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
            > - Stepfun: https://api.stepfun.com/v1/chat/completions

          example: "https://ark.cn-beijing.volces.com/api/v3/chat/completions"
        ApiKey:
          type: string
          description: |
            The parameter used for authentication by the LLM service provider. It is empty by default, but must be provided in production environments.

            > **📌 Important Note**
            >
            > During the test period (within 2 weeks after the AI Agent service is enabled), you can set this parameter value to "zego_test" to use this service.
          example: "zego_test"
        Model:
          type: string
          description: |
            The LLM model. Different LLM service providers support different models, please refer to their official documentation to select the appropriate model.

            > **📌 Important Note**
            >
            > If ApiKey is set to "zego_test", you must use one of the following models:
            > - MiniMax:
            >   - *MiniMax-Text-01*
            > - Volcano Engine (Doubao):
            >   - *doubao-1-5-pro-32k-250115*
            >   - *doubao-1-5-lite-32k-250115*
            > - Aliyun Bailei (Tongyi Qianwen):
            >   - *qwen-plus*
            > - Stepfun:
            >   - *step-2-16k*
          example: "doubao-1-5-lite-32k-250115"
        SystemPrompt:
          type: string
          description: The system prompt of the AI agent. It is the predefined information that is added at the beginning when calling the LLM, used to control the output of the LLM. It can be role settings, prompts, and answer examples.
          example: "You are a friendly assistant"
        Temperature:
          type: number
          description: The higher the value, the more random the output; the lower the value, the more concentrated and determined the output.
          minimum: 0
          maximum: 2
          default: 0.7
          example: 0.7
        TopP:
          type: number
          description: The sampling method. The smaller the value, the stronger the determinism; the larger the value, the stronger the randomness.
          minimum: 0
          maximum: 1
          default: 0.9
          example: 0.9
        Params:
          type: object
          description: Other parameters supported by the LLM service provider, such as the maximum token limit. Different LLM providers support different parameters, please refer to their official documentation and fill in as needed.
          example: {"max_tokens": 16384}
        AddAgentInfo:
          type: boolean
          description: |
            If this value is true, the AI Agent server will include the AI agent information in the request parameters when requesting the LLM service.
            You can use this parameter to execute additional business logic in your custom LLM service.

            The structure of agent_info is as follows:
            - room_id: RTC room ID
            - user_id: User ID
            - agent_instance_id: AI agent instance ID
          default: false
          example: false

    TTS:
      type: object
      required:
        - Vendor
        - Params
      properties:
        Vendor:
          type: string
          description: The TTS service provider. Please refer to [Configuring TTS > TTS Parameters](/aiagent-server/guides/configuring-tts#tts-params) for details.
          enum: ["Aliyun", "ByteDance", "ByteDanceFlowing", "MiniMax", "CosyVoice"]
          example: "ByteDance"
        Params:
          type: object
          description: TTS configuration parameters, in JSON object format. Contains app parameters (for authentication) and other parameters (for adjusting TTS effects). Please refer to [Configuring TTS > Params Parameters](/aiagent-server/guides/configuring-tts#params) for details.

          required:
            - app
          properties:
            app:
              type: object
              description: Used for TTS service authentication, the structure of the app parameter required by different Vendor values is different, please refer to [Configuring TTS > Params Parameters](/aiagent-server/guides/configuring-tts#params) for details.
            other_params:
              type: string
              description: |

                > **📌 Important Note**
                >
                > other_params is not a valid parameter, it is only to explain how to pass the vendor parameters.
                > Except for the app parameter, other parameters are directly passed to the vendor parameters. Please refer to [Configuring TTS > Params Parameters](/aiagent-server/guides/configuring-tts#params) for details.
          example: {
            "app": {
              "appid": "zego_test",
              "token": "zego_test",
              "cluster": "volcano_tts"
            },
            "audio": {
              "voice_type": "zh_female_qingxinnvsheng_mars_bigtts",
              "loudness_ratio": 1.0,
              "speed_ratio": 1.0
            }
          }
        FilterText:
          type: array
          description: |
            Filter the text within the specified punctuation marks from the content returned by the LLM, and then perform speech synthesis.

            Note:
            - The content that should be placed within the specified punctuation marks must be defined in LLM > SystemPrompt.
            - This parameter cannot be updated when updating the AI agent instance.
          items:
            type: object
            required:
              - BeginCharacters
              - EndCharacters
            properties:
              BeginCharacters:
                type: string
                description: The start punctuation mark of the filtered text. For example, if you want to filter the content in (), set it to (.
                example: "("
              EndCharacters:
                type: string
                description: The end punctuation mark of the filtered text. For example, if you want to filter the content in (), set it to ).
                example: ")"
          example: [
            {
              "BeginCharacters": "(",
              "EndCharacters": ")"
            }
          ]
        TerminatorText:
          type: string
          maxLength: 4
          example: "#-#"
          description: |
            Can be used to set the termination text of TTS. If the content in the input TTS text matches the TerminatorText string, the content from the TerminatorText string (including) will not be synthesized for this round of TTS.
            > **📌 Important Note**
            >
            > Only one character can be set for bidirectional streaming.

    ASR:
      type: object
      properties:
        Vendor:
          type: string
          description: ASR provider. Please refer to [Configuring ASR > ASR Parameters](/aiagent-server/guides/configuring-asr#asr-params) for details.
          enum: [Tencent, AliyunParaformer, AliyunGummy, Microsoft]
          default: Tencent
          example: "Tencent"
        Params:
          type: object
          description: Vendor parameters, please refer to [Configuring ASR > Params Parameters](/aiagent-server/guides/configuring-asr#params) for details.
          example: {"engine_model_type": "16k_en", "hotword_list": "zego|10"}
        VADSilenceSegmentation:
          type: number
          description: |
            Set the number of seconds after which two sentences are no longer considered as one.
            Unit is ms, range [200, 2000], default is 500.
            Please refer to [Speech Segmentation Control](/aiagent-server/advanced/speech-segmentation-control) for details.
          minimum: 200
          maximum: 2000
          default: 500
          example: 500
        PauseInterval:
          type: number
          description: |
            Set the number of seconds within which two sentences are considered as one, i.e., ASR multi-sentence concatenation.
            Unit is ms, range [200, 2000].
            Only when this value is greater than VADSilenceSegmentation, ASR multi-sentence concatenation will be enabled.
            Please refer to [Speech Segmentation Control](/aiagent-server/advanced/speech-segmentation-control) for details.
          minimum: 200
          maximum: 2000
          example: 800
        HotWord:
          type: string
          deprecated: true
          description: This parameter has been deprecated. Please set it through the Params vendor parameters.

    MessageHistory:
      type: object
      description: Configuration of the history messages used by the AI agent instance
      properties:
        SyncMode:
          type: integer
          description: |
            Message synchronization mode:
            - 0: Synchronize from the In-app Chat (ZIM)
            - 1: Synchronize through the Messages parameter
          enum: [0, 1]
          default: 0
          example: 0
        Messages:
          type: array
          description: Message list
          maxItems: 100
          items:
            $ref: "#/components/schemas/Message"
        WindowSize:
          type: integer
          format: Int
          description: The number of recent history messages used when calling the LLM service. It affects the LLM context understanding ability, and it is recommended to set it to 10-30.
          minimum: 0
          maximum: 200
          default: 20
          example: 20
        ZIM:
          $ref: "#/components/schemas/ZIM"

    Message:
      type: object
      required:
        - Role
        - Content
      properties:
        Role:
          type: string
          description: |
            The role of the message sender:
            - user: User
            - assistant: AI agent
          enum: [user, assistant]
          example: "user"
        Content:
          type: string
          description: Message content
          example: "Hello, I want to know about the product information"

    ZIM:
      type: object
      description: |
        ZIM-related information.
        <div>
        <br/>
        <strong>📌 Important Note</strong>
        <p>- Only effective when MessageHistory.SyncMode is 0.</p>
        <p>- Please ensure that your project has enabled the ZIM service.</p>
        <p>- Please ensure that you have called the ZIM robot registration interface, and set the returned UserInfo.UserId as the RobotId.</p>
        <p>- It is recommended to register the robot in advance to improve the user information settings and enhance the efficiency of creating AI agent instances.</p>
        </div>
      properties:
        RobotId:
          type: string
          description: ZIM robot ID. That is, the UserInfo.UserId returned by calling the ZIM [register robot](/zim-server/bot/register-bots#request-parameters) interface. It is used to load the chat context between the user and the ZIM robot, and synchronize the messages generated during the conversation to ZIM. If this parameter is empty, the real-time interactive AI Agent backend will randomly generate one.
          example: "@RBT#robot_123"
        LoadMessageCount:
          type: integer
          description: The number of messages to be fetched from the ZIM service as context when creating an AI agent instance. The default is the value of WindowSize (the upper limit).
          minimum: 0
          maximum: 200
          example: 20

    CallbackConfig:
      type: object
      description: |
        Server-side callback configuration

        <div>
        <br/>
        <strong>📌 Important Note</strong>
        <p>Before configuring the following parameters, you need to set the callback address according to [Receiving Callback](/aiagent-server/callbacks/receiving-callback), and understand the specific field descriptions.</p>
        </div>

      properties:
        ASRResult:
          type: integer
          description: Whether to enable server-side callback for ASR results.
          enum: [0, 1]
          default: 0
        LLMResult:
          type: integer
          description: Whether to enable server-side callback for LLM results. If enabled, the ZEGOCLOUD server will return the LLM output result for each sentence.
          enum: [0, 1]
          default: 0
        Interrupted:
          type: integer
          description: Whether to enable server-side callback for the AI agent being interrupted.
          enum: [0, 1]
          default: 0
        UserSpeakAction:
          type: integer
          description: Whether to enable server-side callback for user speech.
          enum: [0, 1]
          default: 0
        AgentSpeakAction:
          type: integer
          description: Whether to enable server-side callback for the AI agent speaking.
          enum: [0, 1]
          default: 0
        UserAudioData:
          type: integer
          description: Whether to enable server-side callback for user speech audio data.
          enum: [0, 1]
          default: 0

    AdvancedConfig:
      type: object
      properties:
        InterruptMode:
          type: integer
          description: |
            The mode of interrupting the AI agent when the user speaks:
            - 0: Interrupt immediately. If the user speaks while the AI is speaking, the AI will be immediately interrupted and stop speaking.
            - 1: Do not interrupt. If the user speaks while the AI is speaking, the AI will not be affected until the content is finished.
          enum: [0, 1]
          default: 0
          example: 0
        MaxIdleTime:
          type: integer
          description: The automatic destruction time of the AI agent instance. If the user (AgentUserId) of the conversation exceeds the MaxIdleTime and is not in the room, the AI agent instance will be automatically deleted by the background and the 1202 exception callback event will be triggered. MaxIdleTime defaults to 120s, with a value range of [10, 1800].
          minimum: 10
          maximum: 1800
          default: 120
          example: 120

    DigitalHuman:
      type: object
      properties:
        DigitalHumanId:
          type: string
          description: Digital human ID
          example: "xiaozhi"
        ConfigId:
          type: string
          description: Digital human configuration ID
          enum: [mobile, web]
          example: "mobile"
        EncodeCode:
          type: string
          description: Digital human video encoding format
          enum: [H264, VP8]
          default: "H264"
          example: "H264"

    ErrorResponse:
      type: object
      properties:
        Code:
          type: integer
          description: Error code
          example: 400
        Message:
          type: string
          description: Error message
          example: "Invalid request parameters"
        RequestId:
          type: string
          description: Request ID
          example: "3151527792559699733"