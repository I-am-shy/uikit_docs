openapi: 3.0.0
info:
  title: open-api-desc
  version: 1.0.0
  contact:
    name: AI Agent API Support
    email: support@zegocloud.com

servers:
  - url: https://aigc-aiagent-api.zegotech.cn
    description: Unified access address (no regional distinction)
  - url: https://aigc-aiagent-api-sha.zegotech.cn
    description: Mainland China (Shanghai)
  - url: https://aigc-aiagent-api-hkg.zegotech.cn
    description: Hong Kong, Macao, and Taiwan (Hong Kong)
  - url: https://aigc-aiagent-api-fra.zegotech.cn
    description: Europe (Frankfurt)
  - url: https://aigc-aiagent-api-lax.zegotech.cn
    description: Western United States (California)
  - url: https://aigc-aiagent-api-bom.zegotech.cn
    description: Asia-Pacific (Mumbai)
  - url: https://aigc-aiagent-api-sgp.zegotech.cn
    description: Southeast Asia (Singapore)

tags:
  - name: agent-instance-control

paths:
  /:
    post:
      tags:
        - agent-instance-control
      summary: SendAgentInstanceLLM
      description: "This interface can be used to, as the user, actively call the LLM service, and based on the response content of the LLM, actively call the TTS service as the AI agent, and send voice messages to the user.Please refer to [AI proactively speaking: proactive invocation of LLM and TTS](./../../guides/proactive-invocation-of-llm-and-tts.mdx) for details and examples."
      operationId: send-agent-instance-llm
      parameters:
        - name: Action
          in: query
          description: |
            > API Prototype Parameter
            >
            > https://aigc-aiagent-api.zegotech.cn?Action=SendAgentInstanceLLM
          required: true
          allowEmptyValue: false
          schema:
            type: string
            enum: [SendAgentInstanceLLM]
          style: form
          explode: true
        - $ref: '../shared-components.yaml#/components/parameters/AppId'
        - $ref: '../shared-components.yaml#/components/parameters/SignatureNonce'
        - $ref: '../shared-components.yaml#/components/parameters/Timestamp'
        - $ref: '../shared-components.yaml#/components/parameters/Signature'
        - $ref: '../shared-components.yaml#/components/parameters/SignatureVersion'
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: "#/components/schemas/SendAgentInstanceLLMRequest"
            example:
              AgentInstanceId: "1907755175297171456"
              Text: "What's the weather like today?"
      responses:
        "200":
          description: Success
          content:
            application/json:
              schema:
                $ref: "#/components/schemas/SendAgentInstanceLLMResponse"

components:
  schemas:
    SendAgentInstanceLLMRequest:
      type: object
      required:
        - AgentInstanceId
        - Text
      properties:
        AgentInstanceId:
          type: string
          description: The unique identifier of the AI agent instance, obtained through the response parameters of the [Create AI Agent Instance](/aiagent-server/api-reference/agent-instance-management/create-agent-instance) interface.
          example: "1907755175297171456"
        Text:
          type: string
          description: The text content sent to the LLM service
          example: "What's the weather like today?"
        SystemPrompt:
          type: string
          description: Whether to temporarily modify the system prompt of the AI agent for this conversation, if needed, fill in this field. If left blank, the system prompt of this conversation will not be changed.
          example: "You are a friendly weather assistant"
        AddQuestionToHistory:
          type: boolean
          description: Whether to add the question to the context
          default: false
          example: true
        AddAnswerToHistory:
          type: boolean
          description: Whether to add the answer to the context
          default: false
          example: true
        Priority:
          type: string
          description: |
            Task priority, the default value is Medium.
          enum:
            - Low
            - Medium
            - High
          default: Medium
          example: Medium
        SamePriorityOption:
          type: string
          description: |
            The interruption strategy when the same priority occurs, the default value is ClearAndInterrupt.
            Optional values:
            1. ClearAndInterrupt：Clear and interrupt
            2. Enqueue：Queue up to wait, the maximum number of queues is 5
          enum:
            - ClearAndInterrupt
            - Enqueue
          default: ClearAndInterrupt
          example: ClearAndInterrupt

    SendAgentInstanceLLMResponse:
      type: object
      properties:
        Code:
          type: integer
          description: Return code. 0 indicates success, other values indicate failure. For more information on error codes and response handling recommendations, please refer to [Return Codes](/aiagent-server/api-reference/return-codes).
          example: 0
        Message:
          type: string
          description: Explanation of the request result
          example: "Success"
        RequestId:
          type: string
          description: Request ID
          example: "8825223157230377926"
