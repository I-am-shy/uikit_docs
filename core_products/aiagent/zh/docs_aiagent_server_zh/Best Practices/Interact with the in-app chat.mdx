# 如何实现IM互动以及与RTC互动联动

本文档旨在指导开发者如何利用 ZIM (ZEGO In-app Messaging) 的实时通讯能力与大模型的自然语言处理能力，构建一个强大且智能的文字互动解决方案，从而提升应用的交互体验。

## 核心概念

在深入实现细节之前，我们先明确几个核心概念：

-   **ZIM (ZEGO In-app Messaging)**: ZEGO 提供的应用内即时通讯服务。它支持文本、图片、文件等多种消息类型，并具备房间管理、用户状态通知等功能，为应用内互动提供坚实基础。
-   **大模型 (Large Language Model, LLM)**: 经过海量文本数据训练的深度学习模型。LLM 能够理解和生成自然语言文本，广泛应用于问答系统、智能对话、文本创作等多种场景。
-   **文字互动**: 指用户在集成 ZIM 服务通过输入文字与大模型进行交互。大模型需能准确理解用户意图，并给出相关的文字回复，实现流畅的对话体验。

## 解决方案架构

典型的 ZIM 与大模型结合的文字互动解决方案架构如下所示：

```mermaid
graph TD
    A[客户端 App] -- ZIM SDK --> B(ZIM 服务端)
    B -- 消息回调/API请求 --> C(业务服务端)
    C -- API 调用 --> D(大模型服务)
    D -- 结果返回 --> C
    C -- ZIM Server API/自有信令 --> B
    B -- ZIM SDK --> A
```

**数据流说明:**

1.  **客户端 App**: 用户在应用内通过集成的 ZIM SDK 发送文字消息。
2.  **ZIM 服务端**: 接收并处理来自客户端的消息。随后，通过消息回调或 API 请求的方式，将用户消息安全、可靠地传递给业务服务端。
3.  **业务服务端**: 作为核心处理中枢，负责：
    *   接收 ZIM 服务端传递的用户消息。
    *   对消息进行必要的预处理，如敏感词过滤、意图初步识别等。
    *   调用选定的大模型服务接口，将处理后的用户消息发送给大模型进行深度分析和内容生成。
    *   接收大模型返回的处理结果。
    *   对大模型结果进行后处理，如格式化输出、内容安全二次校验等。
    *   通过 ZIM Server API 或其他自定义信令通道，将最终的回复消息发送回 ZIM 服务端，再由 ZIM 服务端推送给目标客户端。
4.  **大模型服务**: 接收业务服务端的请求，利用其强大的自然语言处理能力生成恰当的回复内容。

## 快速实现指南

以下步骤将引导您快速搭建一个基础的文字互动解决方案：

### 1. 集成 ZIM SDK 到客户端

首先，在您的客户端应用中集成 ZIM SDK。请根据您的目标平台选择相应的官方文档进行集成：

-   [ZIM Android SDK 集成](https://doc-zh.zego.im/article/13591)
-   [ZIM iOS SDK 集成](https://doc-zh.zego.im/article/13592)
-   [ZIM Web SDK 集成](https://doc-zh.zego.im/article/13593)

### 2. 搭建业务服务端

业务服务端是连接 ZIM 和大模型的桥梁。您可以使用 Node.js, Python, Java, Go 等任何您熟悉的后端技术栈进行搭建。

#### 2.1 接收 ZIM 消息回调

配置 ZIM 服务端，使其能够将消息事件通过回调机制通知到您的业务服务端。详细配置方法请参考：

-   [ZIM 服务端回调](https://doc-zh.zego.im/article/13600)

您的业务服务端需要实现一个 HTTP 接口来接收这些回调。例如，用户发送单聊消息时的回调数据结构可能如下：

```json title="ZIM 消息回调示例 (单聊文本消息)"
{
    "app_id": 12345,
    "event": "zim_send_peer_message", // 事件类型
    "nonce": "abcdefg",
    "signature": "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx", // 安全签名
    "timestamp": 1678886400,
    "message_id": "unique_message_id", // 消息唯一ID
    "from_user_id": "user_A", // 发送方用户ID
    "to_user_id": "user_B",   // 接收方用户ID (或群组ID)
    "type": 1, // 消息类型，1 通常表示文本消息
    "message": "你好，大模型！", // 消息内容
    "extended_data": "" // 扩展数据字段
}
```

#### 2.2 调用大模型服务

收到用户消息后，业务服务端需调用您选定的大模型服务。市面上有多种选择，如 OpenAI (GPT 系列), Anthropic (Claude 系列), Google (Gemini 系列)，或自部署的开源模型。

调用通常通过 HTTP API 完成。请务必查阅相应大模型提供商的 API 文档，了解请求构造、认证方式及响应解析。

以下是使用 Node.js 调用 xxx 系列模型的伪代码示例：

```javascript title="Node.js 调用 xxx大模型 API 示例"
```

**重要提示**: 严禁将 API Key 硬编码到客户端代码或提交到公开代码仓库。推荐使用环境变量或安全的密钥管理服务。

#### 2.3 将回复通过 ZIM 发送回客户端

获取到大模型的回复后，业务服务端需使用 ZIM Server API 将此回复消息发送给原始用户。

具体接口使用请参考 ZIM Server API 文档中的“发送单聊消息”或“发送群组消息”部分：

-   [ZIM Server API 文档](https://doc-zh.zego.im/article/13601)

以下是使用 Node.js 和 `axios` 通过 ZIM Server API 发送消息的示例：

```javascript title="Node.js"
```

### 3. 客户端接收并展示AI回复

客户端的 ZIM SDK 会监听并接收来自业务服务端（经由 ZIM 服务端转发）的 AI 回复消息。您需要在客户端实现消息接收逻辑，并将内容展示在用户界面上。

以下是 ZIM SDK 接收消息的简化示例：

```javascript title="Web"
// 假设 zg 实例已初始化并登录
```

## 进阶功能与优化

构建基础的文字互动功能后，您可以考虑以下进阶功能和优化点，以提升用户体验和系统鲁棒性：

### 上下文管理 (Context Management)

-   **目的**: 实现连贯的多轮对话，让 AI 理解对话的上下文。
-   **方法**: 业务服务端需要为每个用户或会话维护一个对话历史。每次调用大模型时，将近期的对话历史（如最近N轮或一定Token长度内的对话）随同当前用户消息一并发送给大模型。

### 如何在语音互动中保持文字互动的上下文连续性

在实际应用场景中，用户可能会在文字互动和语音互动之间切换。为了保持对话的连贯性和上下文的完整性，您可以通过以下方式将文字互动的上下文关联到语音互动中：

-   **目的**: 
    - 实现文字互动与语音互动的无缝衔接
    - 保持对话上下文的连续性
    - 提供更自然、连贯的用户体验

-   **实现方法**:
    1. 在创建智能体实例并开始语音互动时，配置 MessageHistory 参数：
       - 将 `SyncMode`（消息同步模式）设置为 `0`，表示从 ZIM 同步历史消息
       - 在 MessageHistory 中补充完整的 ZIM 相关信息
    2. 完成以上配置后，创建的智能体实例在语音互动中将自动继承文字互动的上下文

-   **API 参考**：
    - 详细的参数配置请参考 [创建智能体实例 API](https://doc-zh.zego.im/aiagent-server/api-reference/agent-instance-management/create-agent-instance)

### 如何清除上下文 （这块需要提供吗？）

### 异步处理与用户反馈

-   **目的**: 避免因大模型处理耗时较长导致的用户界面卡顿或无响应。
-   **方法**:
    -   客户端发送消息后，可立即在界面上显示“AI 正在思考中…”或类似的等待提示。
    -   业务服务端接收到用户消息后，先快速响应客户端已收到，然后异步调用大模型服务。待大模型返回结果后，再通过 ZIM 将实际回复推送给客户端更新界面。

