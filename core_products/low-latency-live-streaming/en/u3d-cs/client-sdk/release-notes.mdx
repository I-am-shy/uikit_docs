---
articleID: 21115
---



# Release Notes

- - -


## Version 3.21.0 <a id="3.21.0"></a>

**Release Date: 2025-06-23**

**New Features**

1. Support Web projects to set SEI type, capability detection, and set log level functionality

    For related APIs, please refer to [SetSEIConfig](@SetSEIConfig), [CheckSystemRequirements](@CheckSystemRequirements), [SetLogConfig](@SetLogConfig)

2. Support Web projects to listen for local device exception notifications and device state change event callbacks

    For related APIs, please refer to [OnLocalDeviceExceptionOccurred](@OnLocalDeviceExceptionOccurred), [OnVideoDeviceStateChanged](@OnVideoDeviceStateChanged), [OnAudioDeviceStateChanged](OnAudioDeviceStateChanged).

3. Support configuring Karaoke scenario for Web projects

    Support using audio and video configuration suitable for Karaoke scenarios [Karaoke](@ZegoScenarioKaraoke-ZegoScenario) in Web projects, suitable for real-time chorus and online K-song scenarios. Optimizations have been made for latency, sound quality, ear return, and echo cancellation, while also ensuring precise alignment and ultra-low latency for multi-person chorus. For details, please refer to [Scenario-based Audio and Video Configuration](../quick-start/scenario-based-audio-video-configuration.mdx).

    For related APIs, please refer to [SetRoomScenario](@SetRoomScenario)

**Improvements**

1. Updated integrated Express Native SDK to version 3.21.0.
2. Updated integrated Express Web SDK to version 3.9.0.

**Bug Fixes**

<Note title="Note">

The following bug fixes only apply to Web platform interfaces.
</Note>

1. Fixed compilation errors after integrating SDK
2. Fixed other known issues in Unity WebGL.

---

## Version 3.19.0 <a id="3.19.0"></a>

**Release Date: 2025-02-14**

**New Features**

1. Support enabling voice changer effects for media player output sound

    Media player added [EnableVoiceChanger] interface, supporting enabling voice changer effects for media player output sound content, and selecting the desired pitch shifting effect.

    For related APIs, please refer to [ZegoMediaPlayer > EnableVoiceChanger](@EnableVoiceChanger-ZegoMediaPlayer)

2. Support adding mixed output stream to target room

    Stream mixing function supports adding the mixed output stream to a specified room, that is, supporting setting target room information ([targetRoom](@targetRoom)) for the output stream. Each output stream only supports joining one room, and once added, dynamic room updates during stream mixing are not supported. To use server-side interface to implement this function, please refer to [Start Mixing](/live-streaming-server/api-reference/stream-mixing/start-mix) documentation.

**Improvements**

1. Updated integrated Express Native SDK to version 3.19.0.


---

## Version 3.16.2 <a id="3.16.2"></a>

**Release Date: 2024-08-19**

**New Features**

1. Support initiating stream mixing tasks normally when image resource verification fails

    ZegoMixerTask added parameter mixImageCheckMode to control whether stream mixing tasks can be initiated normally when image resources such as background image (backgroundImageURL), input stream placeholder image (inputList.imageInfo.url), and watermark image (watermark.imageURL) fail verification.

    This function is not enabled by default (mixImageCheckMode defaults to 0), indicating strict image verification, meaning that stream mixing tasks can only be initiated normally when rules such as "supported protocols and formats", "image size", and "image resource request successful" are met.

    ZEGO server API stream mixing interface already supports this function. For details, please refer to the CheckImageMode parameter in [Start Mixing](/live-streaming-server/api-reference/stream-mixing/start-mix).

    For related APIs, please refer to [StartMixerTask](@StartMixerTask)

2. Added electronic sound effects

    Electronic sound effects refer to the effect that makes people's speaking and singing sounds have an electronic tone after processing. This function is commonly used in KTV and voice chat room scenarios.

    Call the [SetElectronicEffects] interface before initializing SDK with [CreateEngine] to enable electronic sound effects, and set different modes of electronic tonality and corresponding starting pitch as needed. When this interface is not called, electronic sound effects are disabled by default.

    Developers can also preset common electronic sound effects through the [SetVoiceChangerPreset] interface. Currently, C major electronic sound effects, A minor electronic sound effects, and harmonic minor electronic sound effects are supported.

    For related APIs, please refer to [SetElectronicEffects](@SetElectronicEffects)

3. Added audio equalizer (EQ)

    Support adjusting the gain value of 10 frequency bands to achieve the purpose of adjusting timbre.

    For related APIs, please refer to [SetAudioEqualizerGain](@SetAudioEqualizerGain)

4. Added support for setting and getting audio device volume

    Note: Only Windows, macOS, and Linux support this function.

    Support setting the collection volume of audio devices (speakers or microphones) through [SetAudioDeviceVolume] interface before publishing/playing streams. However, due to system limitations, this interface call may fail. It is recommended to directly use [SetCaptureVolume] and [SetPlayVolume] interfaces to adjust publishing/playing stream volume.

    For related APIs, please refer to [SetAudioDeviceVolume](@SetAudioDeviceVolume), [GetAudioDeviceVolume](@GetAudioDeviceVolume), [SetCaptureVolume](@SetCaptureVolume), [SetPlayVolume](@SetPlayVolume)

5. Support monitoring audio device volume

    Note: Only Windows and macOS platforms support this function.

    Can monitor the volume of audio input or output devices.

    For related APIs, please refer to [StartAudioDeviceVolumeMonitor](@StartAudioDeviceVolumeMonitor), [StopAudioDeviceVolumeMonitor](@StopAudioDeviceVolumeMonitor)

6. Support muting or unmuting audio devices

    Note: Only Windows, macOS, and Linux platforms support this function.

    Audio input or output devices can be muted or unmuted as needed.

    For related APIs, please refer to [MuteAudioDevice](@MuteAudioDevice), [IsAudioDeviceMuted](@IsAudioDeviceMuted)

7. Support getting current audio device information

    Note: Only Windows and macOS platforms support this function.

    Call the [GetCurrentAudioDevice] interface to get information about the audio device currently in use, including device ID and device name, reducing developer workload.

    For related APIs, please refer to [GetCurrentAudioDevice](@GetCurrentAudioDevice)

8. Support pushing static images when camera is turned off

    When the camera is turned off, supports continuously pushing static images in JPEG/JPG, BMP, and HEIF formats. For example, when the host goes to the background, they will actively turn off the camera, and the audience side needs to display an image indicating that the host is temporarily away.

    After initializing SDK and before turning off the camera, set the path of the static image to be pushed through the [SetDummyCaptureImagePath] interface. After starting normal push streaming, call the [EnableCamera] interface to turn off the camera to start pushing static images, and call the [EnableCamera] interface to turn on the camera to end pushing static images.

    For related APIs, please refer to [SetDummyCaptureImagePath](@SetDummyCaptureImagePath)

9. Support throwing [SetDummyCaptureImagePath] exception callback

    For related APIs, please refer to [OnPublisherDummyCaptureImagePathError](@OnPublisherDummyCaptureImagePathError)


10. Media player supports caching network resources locally

    Support caching network resources locally. When playing the same network resource, cached data will be used first to improve user experience.

    For related APIs, please refer to [EnableLocalCache](@EnableLocalCache)

11. When publishing streams, can control whether the stream is allowed for review

    Note: If a stream is set to allow review, but the developer has not initiated a review task, this stream will not be reviewed.

    When calling the review interface, by default all streams in the room will be reviewed. If the client needs to control that a certain stream cannot be reviewed, when calling the [StartPublishingStream] interface to start publishing streams, set the review flag [streamCensorFlag] parameter to 1 (not allowed).

    For related APIs, please refer to [StartPublishingStream](@StartPublishingStream), [ZegoPublisherConfig > StreamCensorFlag](@StreamCensorFlag-ZegoPublisherConfig)


12. H.265 client encoding automatic compatibility strategy added user-level negotiation scope

    Note: To use this function, please contact ZEGOCLOUD Technical Support.

    Control the local client encoding compatibility scope to all publishing users or all users in the room. When there are users in the specified scope who do not support H.265, the local client encoding dynamically falls back.

    For related APIs, please refer to [LoginRoom](@LoginRoom), [StartPublishingStream](@StartPublishingStream), [ZegoPublisherConfig > codecNegotiationType](@codecNegotiationType-ZegoPublisherConfig), [ZegoRoomConfig > capabilityNegotiationTypes](@capabilityNegotiationTypes-ZegoRoomConfig)



**Improvements**

1. Optimized basic beauty function

    ZEGO provides a brand-new basic beauty function to present users with good skin condition and create a natural beauty effect. Developers need to call the [StartEffectsEnv] interface first to initialize the beauty environment before publishing streams, then call the [EnableEffectsBeauty] interface to enable the beauty function. Through the [SetEffectsBeautyParam] interface, you can adjust the degree of whitening, smoothing, sharpening, and reddening as needed to achieve basic beauty capabilities.

    This function is commonly used in video calls, live streaming, and other scenarios.

    For related APIs, please refer to [StartEffectsEnv](@StartEffectsEnv), [StopEffectsEnv](@StopEffectsEnv), [EnableEffectsBeauty](@EnableEffectsBeauty), [SetEffectsBeautyParam](@SetEffectsBeautyParam)

2. Optimized Android platform video rendering function

    Android platform video rendering prioritizes SurfaceTexure rendering.


**Deprecations**

1. Deprecated CDN Plus configuration in the playing stream interface

    Discontinued the concept of Chang Live Streaming and deprecated CDN Plus live streaming related interfaces. To implement live streaming functions, it is recommended to use ZEGO's self-developed [Live Streaming Product](/live-streaming-android/introduction/overview) to achieve higher quality live streaming experience.

    For related APIs, please refer to [ZegoStreamResourceModeCDNPlus](@ZegoStreamResourceModeCDNPlus)


---


## Version 3.14.5 <a id="3.14.5"></a>

**Release Date: 2024-05-07**

**New Features**

1. Mobile development supports iOS 17.0

    Note: Starting from this version, iOS 11.0 and earlier versions are no longer supported.

    Starting from 2024-04-29, all apps submitted to the App Store must support iOS 17.0. For details, please refer to [Apple Developer Website Official Notice](https://developer.apple.com/news/upcoming-requirements/?id=04292024a).

**Improvements**

1. Updated privacy manifest file `PrivacyInfo.xcprivacy` in iOS SDK

    Note: If customers have integrated SDK before version 3.13.2 and want to publish to the App Store, they need to download the latest version of the SDK and copy the PrivacyInfo.xcprivacy file to the corresponding location of the old SDK.

    Please upgrade the privacy manifest file `PrivacyInfo.xcprivacy` in iOS SDK to the new version. For details, please refer to "PrivacyInfo.xcprivacy" under the "ZegoExpressEngine.framework" folder in the SDK package.


---

## Version 3.12.4 <a id="3.12.4"></a>

**Release Date: 2024-01-18**

**New Features**

1. Support copyrighted music plugin

    Note:

    1. To use this function, please contact ZEGOCLOUD Technical Support.

    2. The copyrighted music plugin package cannot be used alone and must be used together with Express SDK.

    Support copyrighted music function modularization. When developers' business scenarios only need to update copyrighted music related code, they can integrate the plugin package separately without updating Express SDK for smooth migration.

**Bug Fixes**

1. Fixed UI lag issue with very low probability when network is abnormal during network switching


---

## Version 3.12.3 <a id="3.12.3"></a>

**Release Date: 2024-01-08**

**Bug Fixes**

1. Fixed occasional crash when calling [EnableAudioCaptureDevice] interface on iOS platform


---

## Version 3.12.2 <a id="3.12.2"></a>

**Release Date: 2024-01-04**

**Bug Fixes**

1. Fixed potential issues


---

## Version 3.11.0 <a id="3.11.0"></a>

**Release Date: 2023-12-13**

**New Features**

1. Added enable or disable playing stream alignment function

    This function is commonly used in KTV and other scenarios that require stream mixing alignment. When playing at the playing end, through the [SetPlayStreamsAlignmentProperty](@SetPlayStreamsAlignmentProperty) interface, control whether the played real-time audio and video streams need precise alignment. If yes, all streams containing precise alignment parameters in the played streams will be aligned; if not, all streams will not be aligned.

    For related APIs, please refer to [SetPlayStreamsAlignmentProperty](@SetPlayStreamsAlignmentProperty)

2. Publishing stream video supports color enhancement

    For situations where the screen colors collected by cameras and other devices are grayish or have low saturation, support enhancing screen colors while protecting human skin tone, making them more vivid and bright, and more in line with human eyes' true visual perception. For details, please refer to [Publish Video Enhancement](/live-streaming-u3d/video/publish-video-enhancement).

    For related APIs, please refer to [EnableColorEnhancement](@EnableColorEnhancement)

3. All network requests support IPv6 protocol

4. Support MJPEG format hardware decoding acceleration

    Note: This function only supports preprocessing of screenshots and does not support other processing (such as rotation, watermark, etc.).

    When the video format output by the capture device is MJPEG, hardware decoding acceleration is enabled by default to prevent problems such as insufficient frame rate caused by insufficient device performance.

    This function is mainly suitable for use on 4K resolution capture devices.

5. Stream mixing supports inputting live protocol streams

    Added support for using live streams as input streams for stream mixing processing; live input stream URLs support both RTMP and HTTP-FLV protocols. This function is suitable for mixing host co-hosting RTC video streams with cloud sports live streams, game live video streams, etc., to implement game or sports live commentary scenarios.


**Improvements**

1. Optimized server-side stream mixing and single stream transcoding capabilities

    Optimized server-side stream mixing and single stream transcoding capabilities, improved encoding efficiency, and improved subjective and objective image quality by more than 5% at the same bitrate.

2. Optimized AEC (Acoustic Echo Cancellation) algorithm for better AEC results

3. Optimized network connection strategy to improve audio and video call experience

4. Optimized Android platform foreground/background switching strategy to solve the problem of audio collection silence in certain specific scenarios or models

5. Optimized multi-device login logic

    After user successfully logs in on device A, device A loses network connection; then uses the same userID to successfully log in on device B. At this time, if device A's network recovers, reconnection will fail and throw error code 1002086, indicating that this userID has logged in on another device.

**Bug Fixes**

1. Fixed crashes caused by hard encoding/decoding on iOS platform in certain cases

2. Fixed missing notification status after camera recovery on iOS platform

3. Fixed crashes caused by decoding on Android platform in certain cases

4. Fixed crashes when N-card hard decoding exits on Windows platform in certain cases

5. Fixed camera restart strategy issue when camera is abnormal on Windows platform


---

## Version 3.10.2 <a id="3.10.2"></a>

**Release Date: 2023-11-20**

**Bug Fixes**

1. Fixed mobile sleep detection module false positives affecting room re-login and publish/playing stream retry logic


---

## Version 3.10.1 <a id="3.10.1"></a>

**Release Date: 2023-11-09**

**Bug Fixes**

1. Fixed black screen issue after enabling low-light enhancement



---

## Version 3.8.1 <a id="3.8.1"></a>

**Release Date: 2023-08-17**

**New Features**

1. Added support for "Smart Cloud Proxy" mode

    Note: To use this function, please contact ZEGOCLOUD Technical Support.

    After developers set "Smart Cloud Proxy" mode, when playing RTC or L3 streams, the direct connection network mode will be tried first. If direct connection network is not available and the current is cellular network, continue to stay in direct connection mode and retry; if direct connection network is not available and the current is non-cellular network, switch to cloud proxy mode. For details, please refer to [Cloud Proxy](/live-streaming-u3d/communication/cloud-proxy).

2. Custom video preprocessing function supports dual output

    Custom video preprocessing function supports "dual output", that is, supporting output of "memory data" and "2D texture data". Developers can use this data to implement third-party beauty functions and perform face detection and beauty with higher performance.

    For related APIs, please refer to [OnCapturedUnprocessedRawData](@OnCapturedUnprocessedRawData), [ZegoVideoBufferTypeGLTexture2DAndRawData](@ZegoVideoBufferTypeGLTexture2DAndRawData)

3. Media player supports setting Http Headers for network resources

    Media player supports setting Http Headers for network resources. Developers can customize and limit access methods for network resources based on this configuration to strengthen resource security protection.

    For related APIs, please refer to [SetHttpHeader](@SetHttpHeader)

4. Support multi-source capture capability

    Oriented towards interactive scenarios with rich audio and video sources such as online KTV, watching movies together, watching matches, video conferences, online education, etc. Multi-source capture provides flexible and easy-to-use audio and video capture source and channel management capabilities, greatly reducing developers' development and maintenance costs.

    Multi-source capture capability shortens, optimizes, and unifies the implementation paths of common capabilities such as screen sharing and audio mixing. From version 3.8.0, you no longer need to implement the above complex capabilities through custom capture. For details, please refer to [Multi-Source Capture](/live-streaming-u3d/communication/multi-source-capture).

    Main capability features:

    1. Publishing channel supports setting or switching multiple audio and video sources.

    2. Supports common capabilities such as screen sharing and audio mixing.

**Improvements**

1. Optimized video rendering effect on iOS platform


---

## Version 3.7.0 <a id="3.7.0"></a>

**Release Date: 2023-07-18**

**New Features**

1. After enabling video large and small stream encoding, in addition to large stream video parameters, added support for setting small stream video parameters

    Note:

    1. Before using this function, you need to call the [SetVideoConfig](@SetVideoConfig) interface first and specify the video encoding format codecID as "ZegoVideoCodecIDH264DualStream (large and small stream encoding)".

    2. The "ratio" of the resolutions set for large and small streams needs to be consistent, otherwise calling the interface will result in an error.

    When the encoding format is specified as "large and small stream encoding", supports setting resolution, frame rate, and bitrate for large and small streams respectively. For details, please refer to [Video Large and Small Streams and Layered Coding](/live-streaming-u3d/video/small-large-video-stream-and-layered-encoding).

    For related APIs, please refer to [SetVideoConfig](@SetVideoConfig), [SetPublishDualStreamConfig](@SetPublishDualStreamConfig)

2. Support dynamically modifying AudioDeviceMode

    Added [SetAudioDeviceMode](@SetAudioDeviceMode) interface for dynamically modifying device audio mode. This configuration determines device volume mode, preprocessing mode, and Mic occupation logic. You can choose according to specific scenarios. For details, please refer to [How to set audio device mode ZegoAudioDeviceMode?](https://www.zegocloud.com/docs/faq/AudioDeviceMod?product=ExpressVideo&platform=unity3d)

    For related APIs, please refer to [SetAudioDeviceMode](@SetAudioDeviceMode)

3. Ten-thousand user range audio and video, game voice support configuring 3D sound effect distance attenuation range

    In ten-thousand user range audio and video and game voice scenarios, supports setting the 3D sound effect distance attenuation range interval [min, max]. When the distance is less than min, the volume will not attenuate as the distance increases; when the distance is greater than max, the other party's sound cannot be heard.

    For related APIs, please refer to [SetReceiveRange](@SetReceiveRange), [SetAudioReceiveRange](@SetAudioReceiveRange)

4. Express Unity3D SDK added support for running in WebGL environment

    Unity projects running in WebGL environment added support for using some functions and interfaces of ZEGO RTC service, including audio and video calls, device management, etc.

    Please refer to [Feature Overview](https://www.zegocloud.com/docs/article/14271) to view specific function and interface support, and refer to [Run Demo Source Code](/real-time-video-u3d-cs/quick-start/run-example-code) and [Integrate SDK](/real-time-video-u3d-cs/quick-start/integrating-sdk) for integration.

**Improvements**

1. Support generating log upload tasks after calling [DestroyEngine] interface

    For related APIs, please refer to [SubmitLog](@SubmitLog)


---


## Version 3.4.2 <a id="3.4.2"></a>

**Release Date: 2023-04-25**

**New Features**

1. Support enabling camera adaptive frame rate

    Note: When the frame rate set by [SetVideoConfig](@SetVideoConfig) is less than the minimum expected frame rate of [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS), the frame rate value set by [SetVideoConfig](@SetVideoConfig) will be used. Due to different hardware and algorithm strategies of different phone manufacturers, the effect of this interface varies on different models or front and rear cameras of the same model.

    When the frame rate set by the publishing user is high, and the ambient lighting is low and cannot display or recognize the subject normally, you can call the [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS) interface to automatically reduce the frame rate within a certain range to increase exposure time, thereby improving video screen brightness. This function is commonly used in live streaming scenarios with high exposure requirements. The [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS) interface needs to be called after calling the [CreateEngine](@CreateEngine) interface to initialize the engine and before starting the camera.

    For related APIs, please refer to [EnableCameraAdaptiveFPS](@EnableCameraAdaptiveFPS)

2. Support setting low-light enhancement

    Note: Need to call [SetLowlightEnhancement](@SetLowlightEnhancement) interface after calling [CreateEngine](@CreateEngine) interface to create the engine.

    When the ambient environment around the publishing user is relatively dark, or the camera frame rate is set high, resulting in dark live streaming screen that cannot display or recognize the subject normally, you can call the [SetLowlightEnhancement](@SetLowlightEnhancement) interface to set low-light enhancement and improve video screen brightness. Low-light enhancement function includes three modes: 1: do not enable low-light enhancement (default), 2: enable low-light enhancement, 3: automatically enable/disable low-light enhancement.

    Developers can choose different low-light enhancement modes according to business scenarios: when you want to judge for yourself whether low-light enhancement is needed, you can control by switching between mode 1 and mode 2; when you want SDK to automatically enhance, you can use mode 3. SDK will automatically judge the lighting environment the user is in and enable/disable low-light enhancement. For details, please refer to [Low-Light Enhancement](/real-time-video-u3d-cs/video/publish-video-enhancement).

    For related APIs, please refer to [SetLowlightEnhancement](@SetLowlightEnhancement)

3. Support enabling system sound card capture

    After enabling sound card capture, the sound played by the system can be mixed into the publishing stream, such as sound played by the browser, sound played by third-party player software, etc., and supports setting capture volume through [SetMixSystemPlayoutVolume](@SetMixSystemPlayoutVolume).

    For related APIs, please refer to [EnableMixSystemPlayout](@EnableMixSystemPlayout), [SetMixSystemPlayoutVolume](@SetMixSystemPlayoutVolume)

**Bug Fixes**

1. Fixed possible crash when app exits

**Deprecations**

1. Starting from version 3.4.2, deprecated support for iOS versions below 11.0, iOS Deployment Target (minimum supported version) raised to iOS 11.0

    For details, please refer to [App Store submission requirement starts April 25](https://developer.apple.com/news/?id=jd9wcyov) and [Xcode 14 Release Notes](https://developer.apple.com/documentation/xcode-release-notes/xcode-14-release-notes#Build-System).

2. Starting from version 3.4.2, iOS SDK no longer supports 32-bit armv7 architecture

    For details, please refer to [Xcode 14 Release Notes](https://developer.apple.com/documentation/xcode-release-notes/xcode-14-release-notes#Build-System).



---

## Version 3.3.0 <a id="3.3.0"></a>

**Release Date: 2023-03-24"


**New Features**

1. Scenario-based audio and video configuration added `StandardVoiceCall` standard voice call scenario
    Scenario-based audio and video configuration added `StandardVoiceCall` standard voice call scenario, suitable for 1v1 pure voice call scenarios. For details, please refer to [Scenario-based Audio and Video Configuration](/live-streaming-u3d/quick-start/scenario-based-audio-video-configuration).

    For related APIs, please refer to [SetRoomScenario](@SetRoomScenario)

2. Support setting minimum values for video frame rate and video resolution

    Added [SetMinVideoFpsForTrafficControl](@SetMinVideoFpsForTrafficControl) and [SetMinVideoResolutionForTrafficControl](@SetMinVideoResolutionForTrafficControl) interfaces. When the user's network is poor and traffic control is enabled, you can set the minimum video frame rate and resolution by calling the interface to help users comprehensively control video display effect.


    For related APIs, please refer to [SetMinVideoFpsForTrafficControl](@SetMinVideoFpsForTrafficControl), [SetMinVideoResolutionForTrafficControl](@SetMinVideoResolutionForTrafficControl)


---

## Version 3.2.0 <a id="3.2.0"></a>

**Release Date: 2023-02-01"


**Improvements**

1. Custom signaling configuration supports extension to 4KB

    Note: The default size of custom signaling configuration is 1KB. If you need to extend to 4KB, please contact ZEGOCLOUD Technical Support for processing.


**Bug Fixes**

1. Fixed null pointer crash when hardware decoding restarts after failure


2. Fixed crash when accessing non-existent API after starting engine on iOS 14


3. Fixed network time module retry failure



---

## Version 3.1.0 <a id="3.1.0"></a>

**Release Date: 2022-12-13"


**New Features**

1. "Ten-thousand User Range Audio and Video" and "Multi-person Real-time State Synchronization" functions support using scenario templates

    Note: To use this function, please contact ZEGOCLOUD Technical Support.

    In virtual scenarios, since each scenario has different map sizes, audio and video interaction gameplay and scales, custom configuration is required for each scenario. After version 3.1.0, "Ten-thousand User Range Audio and Video" and "Multi-person Real-time State Synchronization" support using SDK interfaces and specifying scenarios with template IDs. Configuration items corresponding to template IDs can only be configured through server API. For details, please refer to [Server API - Scenario Template Configuration](live-streaming-server/scenario-service/scenario-template-configure).

    For related APIs, please refer to [templateID](@templateID)

2. "Ten-thousand User Range Audio and Video" and "Multi-person Real-time State Synchronization" functions support using Token basic authentication

    Note: To use this function, please contact ZEGOCLOUD Technical Support.

    When users log in to scenarios, they can carry Token parameters to verify legitimacy.

    For related APIs, please refer to [ZegoSceneParam > token](@token-ZegoSceneParam), [ZegoRangeScene > RenewToken](@RenewToken-ZegoRangeScene)



3. SDK supports setting cloud proxy

    Note: To use this function, please contact ZEGOCLOUD Technical Support.

    By setting the SDK's cloud proxy interface, all traffic corresponding to the SDK is relayed through the cloud proxy server to communicate with RTC. For details, please refer to [Cloud Proxy](/live-streaming-u3d/communication/cloud-proxy).

    For related APIs, please refer to [SetCloudProxyConfig](@SetCloudProxyConfig)




---

## Version 3.0.3 <a id="3.0.3"></a>

**Release Date: 2022-11-29**

**New Features**

1. Support Linux platform

    Express Unity3D SDK now supports Linux x86_64 architecture. For development environment requirements, please refer to [Integrate SDK](/real-time-video-u3d-cs/quick-start/integrating-sdk).

**Bug Fixes**


1. Fixed possible hardware decoding crashes on iOS, macOS, and Windows platforms


2. Fixed issue where others in the room did not receive stream deletion notifications when stopping publishing streams in multi-room mode



---

## Version 3.0.0 <a id="3.0.0"></a>

**Release Date: 2022.11.01**

<Warning title="Note">


This update contains incompatible changes. For details, please refer to the v3.0.0 upgrade guide.

</Warning>



**New Features**

1. Added video first frame callback based on camera opening

    Support callback after SDK plays and renders the first frame of remote camera video data each time remote camera is turned on. Developers can use this callback to count first frame time consumption or update playing stream UI components.

    For related APIs, please refer to [OnPlayerRenderCameraVideoFirstFrame](@OnPlayerRenderCameraVideoFirstFrame)

2. Support querying current SDK feature capabilities

    Since SDK supports feature packaging, some features may have been removed; you can use this function to quickly determine whether the current SDK supports the specified feature.

    For related APIs, please refer to [IsFeatureSupported](@IsFeatureSupported)

3. Added room-level Scenario

    To facilitate developers' quick access and reduce developer access barriers, SDK provides multiple preset scenarios. Developers can choose the corresponding room mode [ZegoScenario](@-ZegoScenario) according to the required scenario. SDK will automatically apply audio and video codecs, audio and video parameters, flow control strategies, and other configurations suitable for that scenario, thereby quickly achieving the best results in that scenario.

    Currently supported scenarios include show live streaming, KTV, standard 1v1 audio and video call, high-quality 1v1 audio and video call, standard voice chat room, high sound quality voice chat room. For details, please refer to [Scenario-based Audio and Video Configuration](/live-streaming-u3d/quick-start/scenario-based-audio-video-configuration).

    For related APIs, please refer to [SetRoomScenario](@SetRoomScenario)

4. Added debug assistant function

    Note: This function is only used during development phase. Do not enable this function in online versions.

    Added [EnableDebugAssistant](@EnableDebugAssistant) interface. When developers call this interface to enable debug assistant function, SDK will print logs to console, and when exceptions occur in calls to other SDK interfaces, UI will pop up error prompts.

    For related APIs, please refer to [EnableDebugAssistant](@EnableDebugAssistant)

**Bug Fixes**

1. Fixed low probability crash when exiting App

**Deprecations**

1. Deprecated three old version scenarios of [ZegoScenario](@-ZegoScenario)

    Deprecated [General], [Communication], [Live] scenarios in [ZegoScenario](@-ZegoScenario) scenario enumeration. For details, please refer to [Scenario-based Audio and Video Configuration](/live-streaming-u3d/quick-start/scenario-based-audio-video-configuration).

2. Deleted interfaces such as [SetDebugVerbose], [SetPlayStreamVideoLayer], [EnableAudioDataCallback], etc. For details, please refer to the upgrade guide for version 3.0.0 and above.


---

## Version 2.23.0 <a id="2.23.0"></a>

**Release Date: 2022.09.13**



**Bug Fixes**


1. Fixed issue where range voice function could still hear sounds of original team members after exiting squad when outside range distance



---



## Version 2.21.2 <a id="2.21.2"></a>

**Release Date: 2022.08.02**

**New Features**

1. Added function to get video rendering Texture2D

    Note: In Unity, texture2D coordinates start from the bottom left, while image coordinates start from the top left, so the Y axis of the Texture2D default rendered screen is flipped.

    In the parent class IVideoSurface of [ZegoExpressEngine](@-ZegoExpressEngine), added interface GetNativeTexture2D for copying a Texture2D of the SDK's current rendering screen for external use.


---

## Version 2.21.1 <a id="2.21.1"></a>

**Release Date: 2022.07.15**

**New Features**

1. Stream mixing supports setting video borders to rounded corners

    When calling [StartMixerTask](@StartMixerTask) interface for stream mixing, developers can set "cornerRadius" (video screen rounded corner radius) through "ZegoMixerInput" type parameter to set video borders to rounded corners. The unit of "cornerRadius" is px, and the value must not exceed half of the shorter of the video screen width and height.

    For related APIs, please refer to [StartMixerTask](@StartMixerTask)

2. Playing stream interface added CDN Plus playing configuration item

    Note: If you want to control playing methods from the cloud through more dimensions such as region and users, please contact ZEGOCLOUD Technical Support for related configuration.

    Playing stream interface added CDN_PLUS playing resource mode ([ZegoStreamResourceMode](@-ZegoStreamResourceMode)). Developers can enable CDN_PLUS playing by stream themselves. CDN Plus playing is a cost-effective playing method with higher live streaming quality than CDN playing but similar price to CDN. For details, please refer to [CDN Plus Playing](/live-streaming-android/introduction/overview).

    For related APIs, please refer to [StartPlayingStream](@StartPlayingStream)

**Bug Fixes**

1. Fixed issue where [DestroyEngine](@DestroyEngine) could cause Unity Editor to crash


2. Fixed possible crash when SDK callbacks are triggered during app exit


---

## Version 2.20.3 <a id="2.20.3"></a>

**Release Date: 2022.07.01**

**New Features**

1. Added audio data monitoring function

    When developers need to get remote users' audio data or need to get data collected by local microphone for other purposes (such as pure audio recording, pure audio third-party monitoring, pure audio real-time analysis), they can call [StartAudioDataObserver](@StartAudioDataObserver) interface to enable real-time audio data monitoring.

    For related APIs, please refer to [StartAudioDataObserver](@StartAudioDataObserver), [StopAudioDataObserver](@StopAudioDataObserver), [OnCapturedAudioData](@OnCapturedAudioData), [OnPlayerAudioData](@OnPlayerAudioData), [OnPlaybackAudioData](@OnPlaybackAudioData), [OnMixedAudioData](@OnMixedAudioData)


---

## Version 2.20.2 <a id="2.20.2"></a>

**Release Date: 2022.06.20**

**Bug Fixes**

1. Fixed probabilistic playing stream failure issue


2. Fixed issue where setting audio device mode before initializing SDK did not take effect


---

## Version 2.20.0 <a id="2.20.0"></a>

**Release Date: 2022-06-13**

**New Features**

1. Support setting stream-level audio and video automatic review

    Note: To use this function, please contact ZEGOCLOUD Technical Support to enable backend service.

    When calling [StartPublishingStream](https://www.zegocloud.com/docs/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2) interface to start publishing streams, developers can set [ZegoStreamCensorshipMode](@-ZegoStreamCensorshipMode) parameter to perform stream-level audio and video automatic review, including review types such as pornography and politics, thereby reducing developers' access difficulty and business maintenance costs.

    For related APIs, please refer to [StartPublishingStream](https://www.zegocloud.com/docs/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2)

**Improvements**

1. Optimized stream mixing precise alignment interface call logic

    Call [StartPublishingStream](https://www.zegocloud.com/docs/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2) interface and set [forceSynchronousNetworkTime](@forceSynchronousNetworkTime-ZegoPublisherConfig) value in [ZegoPublisherConfig](@-ZegoPublisherConfig) to 1. SDK will wait for [OnNetworkTimeSynchronized](@OnNetworkTimeSynchronized) callback notification that NTP network time synchronization is completed before publishing streams. Then call [SetStreamAlignmentProperty](@SetStreamAlignmentProperty) interface to enable stream mixing precise alignment function.

    For related APIs, please refer to [StartPublishingStream](https://www.zegocloud.com/docs/article/api?doc=Express_Video_SDK_API~cs_unity3d~class~ZegoExpressEngine#start-publishing-stream-2), [SetStreamAlignmentProperty](@SetStreamAlignmentProperty), [OnNetworkTimeSynchronized](@OnNetworkTimeSynchronized)

**Bug Fixes**

1. Fixed errors in some interfaces on 32-bit Android phones


    Related interfaces: [LoadResourceFromMediaData](@LoadResourceFromMediaData-ZegoMediaPlayer), [LoadResourceWithPosition](@LoadResourceWithPosition-ZegoMediaPlayer), [LoadCopyrightedMusicResourceWithPosition](@LoadCopyrightedMusicResourceWithPosition-ZegoMediaPlayer)



---


## Version 2.19.0 <a id="2.19.0"></a>

**Release Date: 2022-05-18**

**New Features**

1. Support returning login room and logout room results

    [loginRoom] interface added "callback" parameter, supporting returning login room results from "callback".

    [logoutRoom] interface added "callback" parameter, supporting returning logout room results from "callback".

    For related APIs, please refer to [LoginRoom](@LoginRoom), [LogoutRoom](@LogoutRoom)

2. Added room state change notification [onRoomStateChanged]

    [onRoomStateChanged] callback is triggered when the room's connection state changes, providing more detailed connection state and state change reasons through "ZegoRoomStateChangedReason" parameter.

    For related APIs, please refer to [OnRoomStateChanged](@OnRoomStateChanged)


3. Added enable voice detection function and voice part sound wave callback

    When developers monitor sound wave callbacks, they often only care about the voice part. They can call [StartSoundLevelMonitor](@StartSoundLevelMonitor) interface and pass in "ZegoSoundLevelConfig" to enable VAD voice detection.

    SDK also added parameters for whether voice detection is included in local collection sound wave callback [OnCapturedSoundLevelInfoUpdate](@OnCapturedSoundLevelInfoUpdate) and remote audio sound wave callback [OnRemoteSoundLevelInfoUpdate](@OnRemoteSoundLevelInfoUpdate).

    For related APIs, please refer to [StartSoundLevelMonitor](@StartSoundLevelMonitor), [OnCapturedSoundLevelInfoUpdate](@OnCapturedSoundLevelInfoUpdate), [OnRemoteSoundLevelInfoUpdate](@OnRemoteSoundLevelInfoUpdate)

4. Support getting local and remote uplink and downlink network quality

    Added local and remote users' uplink and downlink network quality callback [OnNetworkQuality](@OnNetworkQuality), defaulting to callback once every two seconds on local and each played remote user's network status (including unknown, excellent, good, fair, poor, network disconnected). When developers want to analyze network conditions on the link or want to know the network status of local and remote users, they can use this function.

    For related APIs, please refer to [OnNetworkQuality](@OnNetworkQuality)


5. Support setting trigger factors for traffic control

    When traffic control is enabled for a specified publishing channel through [EnableTrafficControl](@EnableTrafficControl) interface, you can control whether to start traffic control due to poor remote network conditions through [SetTrafficControlFocusOn](@SetTrafficControlFocusOn) interface.

    For related APIs, please refer to [SetTrafficControlFocusOn](@SetTrafficControlFocusOn)

6. Direct-to-CDN streams support playing through L3

    When publishing directly to CDN, without changing the publishing method, SDK pulls streams from the customer's CDN origin and distributes audio and video content to viewers through L3, controlling origin resources through [ZegoResourceType](@-ZegoResourceType). This function is commonly used in live streaming scenarios.

    For related APIs, please refer to [StartPlayingStream](@StartPlayingStream)

**Bug Fixes**

1. Fixed issue of playing stream failure from CDN



---
